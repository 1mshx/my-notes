Urllib

爬虫：使用程序模拟浏览器，去向服务器发送请求，获取响应信息

爬虫分类：
(1)通用爬虫：功能：访问网页 -> 抓取数据 -> 数据存储 -> 数据处理 -> 提供检索服务
	robots协议：一个约定俗称的协议，添加robots.txt文件，说明本网站哪些内容不可以被抓取，起不到限制作用，自己写的爬虫无需遵守
	缺点：1.抓取的数据大多都是无用的
	2.不能根据用户的需求来精确获取数据
(2)聚焦爬虫：功能 根据需求，实现爬虫程序，抓取需要的数据
	设计思路：1.确定要爬取的url
	2.模拟浏览器通过http协议访问url，获取服务器返回的html代码
	3.解析html字符串

反爬手段：
1.User-Agent：用户代理，是一个特殊字符串头，使得服务器能够识别客户使用的操作系统及版本，CPU类型，浏览器及其版本，浏览器渲染引擎，浏览器语言，浏览器插件等。
2.代理IP：西次代理，快代理
3.验证码访问：打码平台，云打码平台
4.动态加载网页：网站返回的是js数据，并不是网页的真实数据
5.数据加密：分析js代码

基本使用：
	1.导包
	import urllib.request
	2.定义想要访问的网址
	url='http://baidu.com'
	3.模拟浏览器向服务器发送请求
	response=urllib.request.urlopen(url)
	4.获取响应内容
	content=response.read().decode('utf-8')

